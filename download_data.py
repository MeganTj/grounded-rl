#!/usr/bin/env python3
"""
download_and_extract.py

Downloads your VIGORL dataset tarballs from Hugging Face (tracking
dataset downloads in HF metrics), extracts them under DATA_ROOT, and
removes the tarballs.

Usage:
    export DATA_ROOT=/path/to/data
    python download_and_extract.py
"""

import os
import sys
import tarfile
from huggingface_hub import snapshot_download
import shutil

# -----------------------------------------------------------------------------
# 1Ô∏è‚É£ Check DATA_ROOT
# -----------------------------------------------------------------------------
DATA_ROOT = os.getenv("DATA_ROOT")
if not DATA_ROOT:
    sys.stderr.write("Error: DATA_ROOT environment variable is not set.\n")
    sys.stderr.write("Please set DATA_ROOT to the directory where you want to store the data.\n")
    sys.exit(1)

os.makedirs(DATA_ROOT, exist_ok=True)
print(f"‚úÖ DATA_ROOT is set to: {DATA_ROOT}")

# -----------------------------------------------------------------------------
# 2Ô∏è‚É£ Download the entire dataset snapshot (counts as a HF dataset download)
# -----------------------------------------------------------------------------
print("\nüîÑ Downloading dataset snapshot...")
snapshot_download(
    repo_id="gsarch/vigorl_datasets",
    repo_type="dataset",
    local_dir=DATA_ROOT,
    local_dir_use_symlinks=False,   # ensures real files, not symlinks
)

# -----------------------------------------------------------------------------
# 3Ô∏è‚É£ Extract each tarball and clean up
# -----------------------------------------------------------------------------
datasets = [
    "spatial_reasoning",
    "visual_search",
    "web_action",
    "web_grounding",
    # "MCTS_VSTAR_20250514_134727_images_1", # download if need visual search sft data (large ~50GB)
    # "MCTS_VSTAR_20250514_134727_images_2", # download if need visual search sft data (large ~50GB)
]

for ds in datasets:
    tar_path = os.path.join(DATA_ROOT, f"{ds}.tar")
    if not os.path.isfile(tar_path):
        print(f"‚ö†Ô∏è  Warning: {tar_path} not found, skipping.")
        continue

    print(f"\nüìÇ Extracting {ds}.tar ‚Ä¶")
    with tarfile.open(tar_path, "r") as tar:
        tar.extractall(path=DATA_ROOT)

    print(f"üßπ Removing {ds}.tar ‚Ä¶")
    os.remove(tar_path)

    if ds in ["MCTS_VSTAR_20250514_134727_images_1", "MCTS_VSTAR_20250514_134727_images_2"]:
        print(f"üßπ Moving {ds} to visual_search/MCTS_VSTAR_20250514_134727_images ‚Ä¶")
        shutil.move(os.path.join(DATA_ROOT, ds, "*"), os.path.join(DATA_ROOT, "visual_search", "MCTS_VSTAR_20250514_134727_images"))
        print(f"üßπ Removing {ds} ‚Ä¶")
        shutil.rmtree(os.path.join(DATA_ROOT, ds))

print("\nüéâ All done! Your data folders are ready under:")
for ds in datasets:
    print(f" ‚Ä¢ {os.path.join(DATA_ROOT, ds)}")
